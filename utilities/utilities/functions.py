import math
import torch
import numpy as np
import random
from utilities.Pytorch_SSIM import ssim
from utilities.utils import AverageMeter


def val_to_kernel_array(k):
    return k % 2, 1 * (k % 4 > 1), k // 4


def macro_array(k, kernel_array, down_array, up_array):
    array = []

    i1 = 0
    i2 = 0
    i3 = 0

    for i in range(3 * k):
        if (i + 1) % 3 != 0:
            array.append(kernel_array[i1])
            i1 += 1
        else:
            array.append(down_array[i2])
            i2 += 1

    for i in range(2):
        array.append(kernel_array[i1])
        i1 += 1

    for i in range(3 * k):
        if i % 3 == 0:
            array.append(up_array[i3])
            i3 += 1

        else:
            array.append(kernel_array[i1])
            i1 += 1

    return array


def reduced_macro_array(k, encoder_array, bottleneck_array, decoder_array):
    array = []

    for i in range(k):
        for val in encoder_array:
            array.append(val)

    for val in bottleneck_array:
        array.append(val)

    for i in range(k):
        for val in decoder_array:
            array.append(val)

    return array


# This function will display the architectures that were generated by the Controller.
def print_arc(sample_arc):
    """Display a sample architecture in a readable format.

    Args:
        sample_arc: The architecture to display.

    Returns: Nothing.
    """

    # First the Encoder:
    Kernels = ['3, 3, 3', '5, 3, 3', '3, 5, 3', '5, 5, 3', '3, 3, 5', '5, 3, 5', '3, 5, 5', '5, 5, 5']
    Down = ['Max', 'Average', 'Convolution']
    Up = ['Pixel Shuffle', 'Transpose Convolution', 'Bilinear Interpolation']

    Array_Len = len(sample_arc)

    for i in range((Array_Len // 2) - 1):
        if (i + 1) % 3 == 0:
            print(Down[sample_arc[i]])
        else:
            print(Kernels[sample_arc[i]])

    for i in range((Array_Len // 2) - 1, (Array_Len // 2) + 1):
        print(Kernels[sample_arc[i]])

    j = 0
    for i in range((Array_Len // 2) + 1, Array_Len):
        if j % 3 == 0:
            print(Up[sample_arc[i]])
        else:
            print(Kernels[sample_arc[i]])

        j += 1

    print()


def display_time(time):
    time = abs(time)  # In case of Negative Time
    hours = time // (60 * 60)
    minutes = (time // 60) % 60
    seconds = time % 60

    display = 'Total Time: ' + str(int(hours)) + ' hours, ' + str(int(minutes)) + \
              ' minutes, and ' + str(int(seconds)) + ' seconds.'

    print(display)
    print()

    return None


def rand_mod(tensor1, tensor2):
    # Randomly rotates and flips tensors.

    rand_rot = random.randint(0, 3)
    rand_flip = random.randint(2, 3)

    tensor1 = torch.rot90(tensor1, rand_rot, [2, 3])
    tensor1 = torch.flip(tensor1, [rand_flip])

    tensor2 = torch.rot90(tensor2, rand_rot, [2, 3])
    tensor2 = torch.flip(tensor2, [rand_flip])

    return tensor1, tensor2


def get_lr(optimizer):
    for param_group in optimizer.param_groups:
        return param_group['lr']


def augmentate(tensor):
    # Tensors are of size BxCxHxW. We want to rotate and flip about the height and width.

    b, _, _, _ = tensor.size()

    t_90 = 0
    t_180 = 0
    t_270 = 0
    t_fh = 0
    t_fv = 0

    for i in range(b):
        # Rotate
        t_90 = torch.rot90(tensor.clone(), 1, [2, 3])
        t_180 = torch.rot90(tensor.clone(), 2, [2, 3])
        t_270 = torch.rot90(tensor.clone(), 3, [2, 3])

        # Flip

        t_fh = torch.flip(tensor.clone(), [2])
        t_fv = torch.flip(tensor.clone(), [3])

    tensor_out = torch.cat((tensor, t_90, t_180, t_270, t_fh, t_fv), dim=0)

    return tensor_out


# SSIM:
# From: https://github.com/Po-Hsun-Su/pytorch-ssim
def SSIM(images_x, images_y):
    # if images_x.dim() == 5:
    #     images_x = image_reshuffle(images_x[:, 0, :, :, :])
    #     images_y = image_reshuffle(images_y[:, 0, :, :, :])

    ssim_ = ssim(images_x, images_y)
    return ssim_


# PSNR:
# The PSNR is given to us by the formula:
# PSNR = 10 * log_10(1 / MSE)
def PSNR(mse):
    psnr = 10 * torch.log10(1 / mse)
    return psnr


# True PSNR:
# The (True) PSNR is given to us by the formula:
# PSNR(I, J) = 20 * log_10(Max(I)) - 10 * log_10(MSE)
# This formula is more computationally stable since we are not dividing a small value
def True_PSNR(t, x):
    return 20 * torch.log10(t.max()) - 10 * torch.log10(((t - x) ** 2).mean())


def generate_loggers():
    # Image Batches
    loss_batch = AverageMeter()
    loss_original_batch = AverageMeter()
    ssim_batch = AverageMeter()
    ssim_original_batch = AverageMeter()
    psnr_batch = AverageMeter()
    psnr_original_batch = AverageMeter()

    batch_loggers = (loss_batch, loss_original_batch, ssim_batch, ssim_original_batch, psnr_batch, psnr_original_batch)

    # Validation
    loss_meter_val = AverageMeter()
    loss_original_meter_val = AverageMeter()
    ssim_meter_val = AverageMeter()
    ssim_original_meter_val = AverageMeter()
    psnr_meter_val = AverageMeter()
    psnr_original_meter_val = AverageMeter()

    val_loggers = (loss_meter_val, loss_original_meter_val, ssim_meter_val, ssim_original_meter_val, psnr_meter_val,
                   psnr_original_meter_val)

    return batch_loggers, val_loggers


def generate_cyclegan_loggers():
    # Image Batches
    ssim_meter_batch = AverageMeter()
    ssim_original_meter_batch = AverageMeter()
    psnr_meter_batch = AverageMeter()
    psnr_original_meter_batch = AverageMeter()
    loss_DX = AverageMeter()
    loss_DY = AverageMeter()
    loss_GANG = AverageMeter()
    loss_GANF = AverageMeter()
    loss_Cyc_XYX = AverageMeter()
    loss_Cyc_YXY = AverageMeter()
    loss_IX = AverageMeter()
    loss_IY = AverageMeter()
    loss_Sup_XY = AverageMeter()
    loss_Sup_YX = AverageMeter()

    batch_loggers = (ssim_meter_batch, ssim_original_meter_batch, psnr_meter_batch, psnr_original_meter_batch,
                     loss_DX, loss_DY, loss_GANG, loss_GANF, loss_Cyc_XYX, loss_Cyc_YXY, loss_IX, loss_IY, loss_Sup_XY,
                     loss_Sup_YX)

    # Validation
    ssim_meter_val = AverageMeter()
    ssim_original_meter_val = AverageMeter()
    psnr_meter_val = AverageMeter()
    psnr_original_meter_val = AverageMeter()

    val_loggers = (ssim_meter_val, ssim_original_meter_val, psnr_meter_val, psnr_original_meter_val)

    return batch_loggers, val_loggers


def generate_gan_loggers():
    # Image Batches
    ssim_meter_batch = AverageMeter()
    ssim_original_meter_batch = AverageMeter()
    psnr_meter_batch = AverageMeter()
    psnr_original_meter_batch = AverageMeter()
    loss_D = AverageMeter()
    loss_GANG = AverageMeter()
    loss_IY = AverageMeter()
    loss_Sup_XY = AverageMeter()

    batch_loggers = (ssim_meter_batch, ssim_original_meter_batch, psnr_meter_batch, psnr_original_meter_batch,
                     loss_D, loss_GANG, loss_IY, loss_Sup_XY)

    # Validation
    ssim_meter_val = AverageMeter()
    ssim_original_meter_val = AverageMeter()
    psnr_meter_val = AverageMeter()
    psnr_original_meter_val = AverageMeter()

    val_loggers = (ssim_meter_val, ssim_original_meter_val, psnr_meter_val, psnr_original_meter_val)

    return batch_loggers, val_loggers


def drop_weights(state_dict, p=0.8, device='cpu'):
    state_dict_out = state_dict.copy()

    for key in state_dict.keys():
        tensor = state_dict_out[key]
        if tensor.dtype == torch.float32 and list(tensor.size()) != [1]:
            mask = (torch.randn(tensor.size()) < p) * 1.
            tensor = torch.mul(tensor, mask.to(device))

        state_dict_out[key] = tensor

    return state_dict_out


def gaussian_add_weights(state_dict, k=1, device='cpu'):
    state_dict_out = state_dict.copy()

    for key in state_dict.keys():
        tensor = state_dict_out[key]
        if tensor.dtype == torch.float32 and list(tensor.size()) != [1]:
            std = tensor.std().item()
            noise = torch.clip(k * std * torch.randn(tensor.size()), -k * std, k * std)
            tensor += noise.to(device)

        state_dict_out[key] = tensor

    return state_dict_out


def clip_weights(state_dict, k=1, device='cpu'):
    state_dict_out = state_dict.copy()

    for key in state_dict.keys():
        tensor = state_dict_out[key]
        if tensor.dtype == torch.float32:
            std = tensor.std().item()
            tensor = torch.clamp(tensor, -k * std, k * std)

        state_dict_out[key] = tensor

    return state_dict_out


def get_out(out_tensor):
    out_np = out_tensor.permute(0, 2, 3, 1).cpu().numpy()[:, :, :, :]
    out = np.clip((out_np * 255).round(), 0, 255).astype(np.uint8).tolist()

    return out


def transform_tensor(in_tensor, r=0, s=0):
    out_tensor = in_tensor.clone().detach()
    if s == 1:
        out_tensor = torch.flip(in_tensor, dims=[2, 3])
    if r != 0:
        out_tensor = torch.rot90(out_tensor, k=r, dims=[2, 3])

    return out_tensor


def image_np_to_tensor(np_array, i_range=9, j_range=15, crop_size=256):
    np_array_pt = torch.zeros(i_range, j_range, 3, crop_size, crop_size)
    for i in range(i_range):
        for j in range(j_range):
            sample = torch.tensor(np_array[i * crop_size:(i + 1) * crop_size,
                                  j * crop_size:(j + 1) * crop_size, :]).permute(2, 0, 1) / 255.
            np_array_pt[i, j, :, :sample.size()[1], :sample.size()[2]] = sample

    return np_array_pt


def tensor_to_np_image(tensor, i_out=2160, j_out=3840, crop_size=256):
    i_range = math.ceil(i_out / crop_size)
    j_range = math.ceil(j_out / crop_size)
    np_out_zeros = np.zeros([i_range * crop_size, j_range * crop_size, 3], dtype=np.uint8)

    for i in range(i_range):
        for j in range(j_range):
            sample = tensor[i, j, :, :, :].permute(1, 2, 0) * 255
            sample = np.round(sample.numpy()).astype(np.uint8)
            np_out_zeros[i * crop_size:(i + 1) * crop_size, j * crop_size:(j + 1) * crop_size, :] = sample

    np_out = np_out_zeros[:i_out, :j_out, :3]  # Remove the padded components
    return np_out


def random_encoder_generation(kernel_bool=True, up_bool=True):
    encoder = []
    for _ in range(2):
        encoder.append(random.randint(0, 7) if kernel_bool else 0)

    encoder.append(random.randint(0, 2) if up_bool else 0)

    return encoder


def random_decoder_generation(kernel_bool=True, down_bool=True):
    decoder = [random.randint(0, 2) if down_bool else 0]
    for _ in range(2):
        decoder.append(random.randint(0, 7) if kernel_bool else 0)

    return decoder


def random_bottleneck_generation(kernel_bool=True):
    bottleneck = []
    for _ in range(2):
        bottleneck.append(random.randint(0, 7) if kernel_bool else 0)

    return bottleneck


def random_architecture_generation(k_value=3, kernel_bool=True, down_bool=True, up_bool=True, cell_copy=False):
    encoder, decoder = [], []
    if not cell_copy:
        for _ in range(k_value):
            encoder += random_encoder_generation(kernel_bool=kernel_bool, up_bool=up_bool)
            decoder += random_decoder_generation(kernel_bool=kernel_bool, down_bool=down_bool)
    else:
        encoder_temp = random_encoder_generation(kernel_bool=kernel_bool, up_bool=up_bool)
        decoder_temp = random_decoder_generation(kernel_bool=kernel_bool, down_bool=down_bool)
        for _ in range(k_value):
            encoder += encoder_temp
            decoder += decoder_temp

    return encoder + random_bottleneck_generation(kernel_bool=kernel_bool) + decoder


def list_of_ints(arg):
    return list(map(int, arg.split(',')))


def np_softmax(x):
    """Compute softmax values for each sets of scores in x."""
    return np.exp(x) / np.sum(np.exp(x), axis=0)


def generate_w_alphas(k_val=3, s_val=1):
    return s_val * torch.randn(2 * (k_val * (6 + 6 + 3) + 6))


def weights_to_encoder_layer(weights, softmax):
    index = 0
    encoder_layer = []
    for i in range(3):
        if i != 2:
            block = [softmax(weights[index: index + 2]),
                     softmax(weights[index + 2: index + 4]),
                     softmax(weights[index + 4: index + 6])]
            encoder_layer.append(block)
            index += 6
        else:
            sampling = softmax(weights[index: index + 3])
            encoder_layer.append(sampling)

    return encoder_layer, index


def weights_to_bottleneck(weights, softmax):
    index = 0
    bottleneck = []
    for i in range(2):
        block = [softmax(weights[index: index + 2]),
                 softmax(weights[index + 2: index + 4]),
                 softmax(weights[index + 4: index + 6])]
        bottleneck.append(block)
        index += 6

    return bottleneck, index


def weights_to_decoder_layer(weights, softmax):
    index = 0
    decoder_layer = []
    for i in range(3):
        if i != 0:
            block = [softmax(weights[index: index + 2]),
                     softmax(weights[index + 2: index + 4]),
                     softmax(weights[index + 4: index + 6])]
            decoder_layer.append(block)
            index += 6
        else:
            sampling = softmax(weights[index: index + 3])
            decoder_layer.append(sampling)

    return decoder_layer, index


def w_alphas_to_alphas(w_alphas, k_val=3):
    index = 0
    softmax = torch.nn.Softmax(dim=0)

    # Encoder
    encoder = []
    for i in range(k_val):
        encoder_layer, index = weights_to_encoder_layer(w_alphas[index:index + 16], softmax)
        encoder.append(encoder_layer)
        index += 16

    # Bottleneck
    bottleneck, index = weights_to_bottleneck(w_alphas[index:index + 12], softmax)
    index += 12

    # Decoder
    decoder = []
    for i in range(k_val):
        decoder_layer, index = weights_to_decoder_layer(w_alphas[index:index + 16], softmax)
        decoder.append(decoder_layer)
        index += 16

    return encoder + [bottleneck] + decoder


def generate_alphas(k_val=3, blocks=3, randomize=False):
    encoder = []
    bottleneck = []
    decoder = []
    block = [0.5, 0.5]
    block_reshape = [0.33, 0.33, 0.33]
    for k in range(k_val):
        encoder_temp, decoder_temp = [], []
        if randomize:
            block_reshape = np_softmax(np.random.rand(3)).tolist()
        decoder_temp.append(block_reshape)
        for _ in range(2):
            # DRC Blocks
            DRC_temp = [[], [], []]
            for _ in range(blocks):
                for i in range(3):
                    if randomize:
                        block = np_softmax(np.random.rand(2)).tolist()
                    DRC_temp[i].append(block)

            encoder_temp.append(DRC_temp[0])
            decoder_temp.append(DRC_temp[1])

        if randomize:
            block_reshape = np_softmax(np.random.rand(3)).tolist()
        encoder_temp.append(block_reshape)

        encoder.append(encoder_temp)
        decoder.append(decoder_temp)

    for _ in range(2):
        bottleneck_temp = []
        for _ in range(blocks):
            if randomize:
                block = np_softmax(np.random.rand(2)).tolist()
            bottleneck_temp.append(block)
        bottleneck.append(bottleneck_temp)

    return encoder + [bottleneck] + decoder


def generate_controller_distribution(controller, number=1000):
    architectures = []
    number = 1000
    for i in range(number):
        with torch.no_grad():
            controller()
        architectures.append(controller.sample_arc)
    architectures_array = np.array(architectures)
    dict_arc = {}
    for i in range(len(architectures_array[-1])):
        dict_arc[i] = {}
        if not (i + 1) % 3:
            for j in range(3):
                dict_arc[i][j] = np.count_nonzero(architectures_array[:, i] == j) / number
        else:
            for j in range(8):
                dict_arc[i][j] = np.count_nonzero(architectures_array[:, i] == j) / number
    argmax_arc = []
    print('\n' + '-' * 120)
    print('Controller Distribution:')
    for key in dict_arc.keys():
        print(key, dict_arc[key])
        argmax_arc.append(np.argmax(list(dict_arc[key].values())))
    print('Architecture argmax:', argmax_arc)
    print('\n' + '-' * 120)


def shared_weights_to_fixed_weights(shared_model, fixed_model, architecture):
    dict_shared = shared_model.state_dict()
    dict_out = fixed_model.state_dict()

    dict_out['init_conv.0.weight'] = dict_shared['init_conv.0.weight']
    dict_out['init_conv.0.bias'] = dict_shared['init_conv.0.bias']
    dict_out['init_conv.1.weight'] = dict_shared['init_conv.1.weight']

    for index, path in enumerate(architecture):
        weight_path_old = 'layers.{index}'.format(index=index)
        weight_path_new = 'layers.{index}'.format(index=index)

        # Resampling
        if index % 3 == 2:
            if index < len(architecture) // 2:
                if path != 2:
                    for end in ['weight', 'bias']:
                        # Get the weights and biases
                        weight_path_old_k = weight_path_old + '.conv.' + end
                        weight_path_new_k = weight_path_new + '.conv.' + end
                        dict_out[weight_path_new_k] = dict_shared[weight_path_old_k]
                else:
                    for end in ['weight', 'bias']:
                        # Get the weights and biases
                        weight_path_old_k = weight_path_old + '.downconv.' + end
                        weight_path_new_k = weight_path_new + '.down.' + end
                        dict_out[weight_path_new_k] = dict_shared[weight_path_old_k]

                # Get the ReLU activation weight
                weight_path_old_relu = weight_path_old + '.relu.weight'
                weight_path_new_relu = weight_path_new + '.relu.weight'
                dict_out[weight_path_new_relu] = dict_shared[weight_path_old_relu]
            else:
                # Get the ReLU and Convolution weight
                for end in ['weight', 'bias']:
                    weight_path_old_relu = weight_path_old + '.conv.' + end
                    weight_path_new_relu = weight_path_new + '.conv.' + end
                    dict_out[weight_path_new_relu] = dict_shared[weight_path_old_relu]

                weight_path_old_relu = weight_path_old + '.relu.weight'
                weight_path_new_relu = weight_path_new + '.relu.weight'
                dict_out[weight_path_new_relu] = dict_shared[weight_path_old_relu]

                if path != 0:
                    for end in ['weight', 'bias']:
                        # Get the weights and biases
                        if path == 2:
                            str_val = '.BL.0.'
                            str_out = '.up.0.'
                        else:
                            str_val = '.convT.'
                            str_out = '.up.'

                        weight_path_old_end = weight_path_old + str_val + end
                        weight_path_new_end = weight_path_new + str_out + end
                        dict_out[weight_path_new_end] = dict_shared[weight_path_old_end]

        # Kernels
        else:
            kernel_array = val_to_kernel_array(path)
            for index_k, k in enumerate(kernel_array):
                weight_path_old_k = weight_path_old + '.graph.'
                weight_path_new_k = weight_path_new + '.path.'
                for end in ['weight', 'bias']:
                    # Get the weights and biases
                    weight_path_old_k_end = weight_path_old_k + str(2 * index_k) + '.' + str(k) + '.' + end
                    weight_path_new_k_end = weight_path_new_k + str(index_k) + '.' + str(0) + '.' + end
                    dict_out[weight_path_new_k_end] = dict_shared[weight_path_old_k_end]

                # Get the ReLU activation weight
                weight_path_old_relu = weight_path_old_k + str(2 * index_k + 1) + '.' + 'weight'
                weight_path_new_relu = weight_path_new_k + str(index_k) + '.1.' + 'weight'
                dict_out[weight_path_new_relu] = dict_shared[weight_path_old_relu]

    dict_out['final_conv.0.weight'] = dict_shared['final_conv.0.weight']
    dict_out['final_conv.0.bias'] = dict_shared['final_conv.0.bias']
    dict_out['final_conv.1.weight'] = dict_shared['final_conv.1.weight']

    return dict_out
